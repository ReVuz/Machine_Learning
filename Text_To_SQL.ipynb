{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "name": "Text-To-SQL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "TPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30748,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReVuz/Machine_Learning/blob/main/Text_To_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T02:10:56.426287Z",
          "iopub.execute_input": "2024-07-19T02:10:56.426648Z",
          "iopub.status.idle": "2024-07-19T02:10:56.434305Z",
          "shell.execute_reply.started": "2024-07-19T02:10:56.426618Z",
          "shell.execute_reply": "2024-07-19T02:10:56.433195Z"
        },
        "trusted": true,
        "id": "i31IFKEI-FqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "niPwDyGWynTL",
        "execution": {
          "iopub.status.busy": "2024-07-18T23:53:13.376783Z",
          "iopub.execute_input": "2024-07-18T23:53:13.377171Z",
          "iopub.status.idle": "2024-07-18T23:53:27.040446Z",
          "shell.execute_reply.started": "2024-07-18T23:53:13.377142Z",
          "shell.execute_reply": "2024-07-18T23:53:27.039478Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict, load_dataset, interleave_datasets, load_from_disk\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
        "import torch\n",
        "import time\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "x_T2uwfvq9Ku",
        "execution": {
          "iopub.status.busy": "2024-07-18T23:53:29.878759Z",
          "iopub.execute_input": "2024-07-18T23:53:29.879653Z",
          "iopub.status.idle": "2024-07-18T23:53:31.150965Z",
          "shell.execute_reply.started": "2024-07-18T23:53:29.87962Z",
          "shell.execute_reply": "2024-07-18T23:53:31.150182Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "kqsauoQnrTJk",
        "execution": {
          "iopub.status.busy": "2024-07-18T23:53:35.389183Z",
          "iopub.execute_input": "2024-07-18T23:53:35.389571Z",
          "iopub.status.idle": "2024-07-18T23:53:35.425034Z",
          "shell.execute_reply.started": "2024-07-18T23:53:35.389542Z",
          "shell.execute_reply": "2024-07-18T23:53:35.424068Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name='t5-small'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "original_model = original_model.to('cuda')"
      ],
      "metadata": {
        "id": "bl8lGgKXzWZV",
        "execution": {
          "iopub.status.busy": "2024-07-19T02:25:31.513457Z",
          "iopub.execute_input": "2024-07-19T02:25:31.514362Z",
          "iopub.status.idle": "2024-07-19T02:25:32.719844Z",
          "shell.execute_reply.started": "2024-07-19T02:25:31.514326Z",
          "shell.execute_reply": "2024-07-19T02:25:32.718688Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    dataset = load_from_disk(\"merged_dataset\")\n",
        "    print(\"Loaded Merged Dataset\")\n",
        "except:\n",
        "    dataset_scc_train = load_dataset(\"b-mc2/sql-create-context\", split='train[:80%]')\n",
        "    dataset_scc_test  = load_dataset(\"b-mc2/sql-create-context\", split='train[-20%:-10%]')\n",
        "    dataset_scc_val   = load_dataset(\"b-mc2/sql-create-context\", split='train[-10%:]')\n",
        "\n",
        "    dataset_tts_train = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[:80%]')\n",
        "    dataset_tts_train = dataset_tts_train.remove_columns(['source', 'text'])\n",
        "    dataset_tts_train = dataset_tts_train.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
        "    dataset_tts_test  = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-20%:-10%]')\n",
        "    dataset_tts_test  = dataset_tts_test.remove_columns(['source', 'text'])\n",
        "    dataset_tts_test  = dataset_tts_test.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
        "    dataset_tts_val   = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-10%:]')\n",
        "    dataset_tts_val   = dataset_tts_val.remove_columns(['source', 'text'])\n",
        "    dataset_tts_val   = dataset_tts_val.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
        "\n",
        "    dataset_ks_train  = load_dataset(\"knowrohit07/know_sql\", split='validation[:80%]')\n",
        "    dataset_ks_test   = load_dataset(\"knowrohit07/know_sql\", split='validation[-20%:-10%]')\n",
        "    dataset_ks_val    = load_dataset(\"knowrohit07/know_sql\", split='validation[-10%:]')\n",
        "\n",
        "    dataset = DatasetDict({ 'train': interleave_datasets([dataset_scc_train, dataset_tts_train, dataset_ks_train]),\n",
        "                            'test': interleave_datasets([dataset_scc_test, dataset_tts_test, dataset_ks_test]),\n",
        "                            'validation': interleave_datasets([dataset_scc_val, dataset_tts_val, dataset_ks_val])})\n",
        "\n",
        "    dataset.save_to_disk(\"merged_dataset\")\n",
        "    print(\"Merged and Saved Dataset\")\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "haZAKlIZzdUt",
        "execution": {
          "iopub.status.busy": "2024-07-18T23:54:17.139248Z",
          "iopub.execute_input": "2024-07-18T23:54:17.139665Z",
          "iopub.status.idle": "2024-07-18T23:54:17.170312Z",
          "shell.execute_reply.started": "2024-07-18T23:54:17.139633Z",
          "shell.execute_reply": "2024-07-18T23:54:17.169455Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['test'][0]"
      ],
      "metadata": {
        "id": "rD0C7Vg2zklS",
        "execution": {
          "iopub.status.busy": "2024-07-18T23:54:26.904385Z",
          "iopub.execute_input": "2024-07-18T23:54:26.904749Z",
          "iopub.status.idle": "2024-07-18T23:54:26.914091Z",
          "shell.execute_reply.started": "2024-07-18T23:54:26.904721Z",
          "shell.execute_reply": "2024-07-18T23:54:26.912807Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREPROCESS THE DATASET**\n",
        "You need to convert the datasets into explicit instructions for the LLM.\n",
        "\n",
        "Then preprocess the prompt-response dataset into tokens and pull out their input_ids."
      ],
      "metadata": {
        "id": "42P1lDlTz2Co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "\n",
        "#     print(len(example[\"question\"]))\n",
        "    start_prompt = \"Tables:\\n\"\n",
        "    middle_prompt = \"\\n\\nQuestion:\\n\"\n",
        "    end_prompt = \"\\n\\nAnswer:\\n\"\n",
        "\n",
        "    data_zip = zip(example['context'], example['question'])\n",
        "    prompt = [start_prompt + context + middle_prompt + question + end_prompt for context, question in data_zip]\n",
        "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "    example['labels'] = tokenizer(example['answer'], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "#     print(prompt[0])\n",
        "#     print()\n",
        "\n",
        "    return example\n",
        "\n",
        "# The dataset actually contains 3 diff splits: train, validation, test.\n",
        "# The tokenize_function code is handling all data across all splits in batches.\n",
        "\n",
        "try:\n",
        "    tokenized_datasets = load_from_disk(\"tokenized_datasets\")\n",
        "    print(\"Loaded Tokenized Dataset\")\n",
        "except:\n",
        "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns(['question', 'context', 'answer'])\n",
        "\n",
        "    tokenized_datasets.save_to_disk(\"tokenized_datasets\")\n",
        "    print(\"Tokenized and Saved Dataset\")"
      ],
      "metadata": {
        "id": "xZEW-Ld1z8pH",
        "execution": {
          "iopub.status.busy": "2024-07-18T23:59:07.506205Z",
          "iopub.execute_input": "2024-07-18T23:59:07.506899Z",
          "iopub.status.idle": "2024-07-18T23:59:07.531083Z",
          "shell.execute_reply.started": "2024-07-18T23:59:07.506863Z",
          "shell.execute_reply": "2024-07-18T23:59:07.530071Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_datasets.keys())\n",
        "print(tokenized_datasets['train'][0].keys())\n",
        "print(tokenized_datasets['train'][0]['input_ids'][:10])\n",
        "print(tokenized_datasets['train'][0]['labels'][:10])\n",
        "print(tokenized_datasets)"
      ],
      "metadata": {
        "id": "GgIqsTVv0KiS",
        "execution": {
          "iopub.status.busy": "2024-07-18T23:59:17.104034Z",
          "iopub.execute_input": "2024-07-18T23:59:17.104769Z",
          "iopub.status.idle": "2024-07-18T23:59:17.113498Z",
          "shell.execute_reply.started": "2024-07-18T23:59:17.104736Z",
          "shell.execute_reply": "2024-07-18T23:59:17.112467Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shapes of the datasets:\")\n",
        "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
        "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
        "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
        "\n",
        "print(tokenized_datasets)"
      ],
      "metadata": {
        "id": "8jge6iXV0NOm",
        "execution": {
          "iopub.status.busy": "2024-07-18T23:59:19.568018Z",
          "iopub.execute_input": "2024-07-18T23:59:19.568646Z",
          "iopub.status.idle": "2024-07-18T23:59:19.57428Z",
          "shell.execute_reply.started": "2024-07-18T23:59:19.568616Z",
          "shell.execute_reply": "2024-07-18T23:59:19.573489Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST THE MODEL WITH ZERO SHOT INFERENCING**"
      ],
      "metadata": {
        "id": "wnqBNfXl0PYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "\n",
        "question = dataset['test'][index]['question']\n",
        "context = dataset['test'][index]['context']\n",
        "answer = dataset['test'][index]['answer']\n",
        "\n",
        "prompt = f\"\"\"Tables:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "inputs = inputs.to('cuda')\n",
        "\n",
        "output = tokenizer.decode(\n",
        "    original_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=200,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')\n"
      ],
      "metadata": {
        "id": "SXu6MRHQ0VKE",
        "execution": {
          "iopub.status.busy": "2024-07-18T23:59:22.576456Z",
          "iopub.execute_input": "2024-07-18T23:59:22.577326Z",
          "iopub.status.idle": "2024-07-18T23:59:22.61958Z",
          "shell.execute_reply.started": "2024-07-18T23:59:22.577294Z",
          "shell.execute_reply": "2024-07-18T23:59:22.618652Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PERFORM FULL FINE TUNING**\n",
        "2 Epochs\n",
        "5e-3\n",
        "Time Taken = 2h 49m 1s on a laptop with a GeForce RTX 3070 GPU\n",
        "\n",
        "Training Loss = 0.023100\n",
        "\n",
        "Validation Loss = 0.013285"
      ],
      "metadata": {
        "id": "CE_mT_lV0gwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(\"finetuned_model_2_epoch\")\n",
        "    finetuned_model = finetuned_model.to('cuda')\n",
        "    to_train = False\n",
        "\n",
        "except:\n",
        "    to_train = True\n",
        "    finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "    finetuned_model = finetuned_model.to('cuda')\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "mTooHbzz0emY",
        "execution": {
          "iopub.status.busy": "2024-07-18T23:59:26.539065Z",
          "iopub.execute_input": "2024-07-18T23:59:26.539704Z",
          "iopub.status.idle": "2024-07-18T23:59:27.747306Z",
          "shell.execute_reply.started": "2024-07-18T23:59:26.539662Z",
          "shell.execute_reply": "2024-07-18T23:59:27.746486Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "if to_train:\n",
        "    output_dir = f'./sql-training-{str(int(time.time()))}'\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        learning_rate=5e-3,\n",
        "        num_train_epochs=2,\n",
        "        per_device_train_batch_size=16,     # batch size per device during training\n",
        "        per_device_eval_batch_size=16,      # batch size for evaluation\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=50,\n",
        "        evaluation_strategy='steps',        # evaluation strategy to adopt during training\n",
        "        eval_steps=500,                     # number of steps between evaluation\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=finetuned_model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_datasets['train'],\n",
        "        eval_dataset=tokenized_datasets['validation'],\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    finetuned_model.save_pretrained(\"finetuned_model_2_epoch\")"
      ],
      "metadata": {
        "id": "dg4xnEJE0pny",
        "execution": {
          "iopub.status.busy": "2024-07-18T23:59:30.119138Z",
          "iopub.execute_input": "2024-07-18T23:59:30.119509Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(\"finetuned_model_2_epoch\")\n",
        "finetuned_model = finetuned_model.to('cuda')"
      ],
      "metadata": {
        "id": "FeJWGzsG0sM7",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test the Fine Tuned Model with Zero Shot Inferencing**"
      ],
      "metadata": {
        "id": "MrGz7jFO0vIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "# index = len(dataset['test'])-200\n",
        "\n",
        "question = dataset['test'][index]['question']\n",
        "context = dataset['test'][index]['context']\n",
        "answer = dataset['test'][index]['answer']\n",
        "\n",
        "prompt = f\"\"\"Tables:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "inputs = inputs.to('cuda')\n",
        "\n",
        "output = tokenizer.decode(\n",
        "    finetuned_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=200,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\n",
        "print(dash_line)\n",
        "print(f'FINE-TUNED MODEL - ZERO SHOT:\\n{output}')"
      ],
      "metadata": {
        "id": "7KNLTGp10tjf",
        "execution": {
          "iopub.status.busy": "2024-07-19T02:19:36.238893Z",
          "iopub.execute_input": "2024-07-19T02:19:36.239555Z",
          "iopub.status.idle": "2024-07-19T02:19:36.531059Z",
          "shell.execute_reply.started": "2024-07-19T02:19:36.239525Z",
          "shell.execute_reply": "2024-07-19T02:19:36.527007Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Model Quantitatively (with ROUGE Metric)**"
      ],
      "metadata": {
        "id": "NJD_zUlg01ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inferences for test dataset. Do 25 only, due to time it takes.\n",
        "\n",
        "questions = dataset['test'][0:25]['question']\n",
        "contexts = dataset['test'][0:25]['context']\n",
        "human_baseline_answers = dataset['test'][0:25]['answer']\n",
        "\n",
        "original_model_answers = []\n",
        "finetuned_model_answers = []\n",
        "\n",
        "for idx, question in enumerate(questions):\n",
        "\n",
        "    prompt = f\"\"\"Tables:\n",
        "{contexts[idx]}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "    input_ids = input_ids.to('cuda')\n",
        "\n",
        "    human_baseline_text_output = human_baseline_answers[idx]\n",
        "\n",
        "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=300))\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    original_model_answers.append(original_model_text_output)\n",
        "\n",
        "    finetuned_model_outputs = finetuned_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=300))\n",
        "    finetuned_model_text_output = tokenizer.decode(finetuned_model_outputs[0], skip_special_tokens=True)\n",
        "    finetuned_model_answers.append(finetuned_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_baseline_answers, original_model_answers, finetuned_model_answers))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_answers', 'original_model_answers', 'finetuned_model_answers'])\n",
        "# df"
      ],
      "metadata": {
        "id": "UYzk8Fmu02eC",
        "execution": {
          "iopub.status.busy": "2024-07-19T02:19:42.794097Z",
          "iopub.execute_input": "2024-07-19T02:19:42.794915Z",
          "iopub.status.idle": "2024-07-19T02:19:58.681448Z",
          "shell.execute_reply.started": "2024-07-19T02:19:42.794883Z",
          "shell.execute_reply": "2024-07-19T02:19:58.680368Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T02:21:08.238847Z",
          "iopub.execute_input": "2024-07-19T02:21:08.239216Z",
          "iopub.status.idle": "2024-07-19T02:21:23.430433Z",
          "shell.execute_reply.started": "2024-07-19T02:21:08.239189Z",
          "shell.execute_reply": "2024-07-19T02:21:23.42914Z"
        },
        "trusted": true,
        "id": "rcjMxzOj-Fra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute ROUGE score for this subset of the data."
      ],
      "metadata": {
        "id": "_pQ8SnIw06Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_answers,\n",
        "    references=human_baseline_answers[0:len(original_model_answers)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "\n",
        "\n",
        "finetuned_model_results = rouge.compute(\n",
        "    predictions=finetuned_model_answers,\n",
        "    references=human_baseline_answers[0:len(finetuned_model_answers)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "print('FINE-TUNED MODEL:')\n",
        "print(finetuned_model_results)"
      ],
      "metadata": {
        "id": "UtqHlrl3062I",
        "execution": {
          "iopub.status.busy": "2024-07-19T02:21:26.578385Z",
          "iopub.execute_input": "2024-07-19T02:21:26.578698Z",
          "iopub.status.idle": "2024-07-19T02:21:27.550931Z",
          "shell.execute_reply.started": "2024-07-19T02:21:26.578646Z",
          "shell.execute_reply": "2024-07-19T02:21:27.549899Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}